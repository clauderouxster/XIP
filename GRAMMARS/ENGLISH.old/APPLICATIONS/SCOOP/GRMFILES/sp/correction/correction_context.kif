kif:
//use('kifregex');
use('kifsys');

loadin(_paths[1] + _sep + "testLM.kif");

string path_spell = _paths[1] +_sep + ".." +_sep + "modelAndLexicon" ;

fst f(kifsys.env("NTM_ROOT")+"/SOURCEFST/FORSEM/nvlex-scoop.fst", "", 0, false);

//fst f(_paths[1] +"/../../NTMFILES/SOURCEFST/FORSEM/nvlex-scoop.fst", "", 0, false);
//fst f(_paths[1] +"/../nvlex-scoop.fst", "", 0, false);
int MAX_EDIT = 3;
float singleEditProb = 0.01;
automaton au;
au.loadlemma(path_spell+_sep+'updatedLexicon', "|");
//string context = "lemma";
string context = "pos";
map lm;
if (context == "pos"){
   readLM(path_spell+_sep+"lm3.pos", lm);
}
else if (context == "lemma"){
     time mt;
     //print(mt);
     readLM(path_spell +_sep + 'lm2.lemma', lm);
     time new_mt;
     println("TIME TO READ LM:", new_mt-mt);
}
parser Parser;


function correct(node Node) {    
     smap vres;
     string pos;
     Parser.getgrammar(Node);
     string s=Node.surface();
     map nlems;
     if (s.size() >3){
          //println("INITIAL S ", s, Node.pos());
          MAX_EDIT = min(MAX_EDIT, s.size()/2-1);
          nlems  = au.editdistance(s, 0, a_nocase)[0];
          //println("edit dist 0:", nlems);
          string lem;
          boolean hasNotGuessedVariants = false;
          for (lem in nlems){
               if (not "Guess" in lem){
                    hasNotGuessedVariants = true;
               }
          }
          if (nlems.size() ==0){
          //not hasNotGuessedVariants){
          nlems = au.editdistance(s, 1, a_first|a_change|a_delete|a_insert|a_switch|a_nocase)[0];
          //println("edit dist 1:", nlems);
          if (nlems.size()==0 and MAX_EDIT>1){
               nlems =  au.editdistance(s, MAX_EDIT, a_first|a_change|a_delete|a_insert|a_switch|a_nocase)[0];
               //println("edit dist 2:", nlems);
          }
          }
          string corr_lemma_withFeats;
          boolean addNewReading = false;
          fmap bestReading;

          for (corr_lemma_withFeats in nlems){
               string corr_lemma = corr_lemma_withFeats.split("+")[0];
               string xip_feats = f.up(corr_lemma)["\t":][1:];
               if (xip_feats=="+?"){
                    // if current correction wasn't found in fst: keep original node features and PoS tag
                    vres = Node.features();
                    vres.pop("lemme");
                    vres.pop("surface");
                    pos = Node.pos();
               }
               else{
                    // add new reading with new features
                    svector vfeats=xip_feats.split("+");
                    pos=Parser.parsefeatures(vfeats,vres);
                    if (pos==""){
                         pos = Node.pos();
                    }
               }
               vres["spellch"]="+";
               Node.lemma(corr_lemma, pos, vres);
               addNewReading=true;
          }

          return(addNewReading);
     }
     return(false);
}


function correct_context_lemma(node Node, string leftLemma, string rightLemma) {
     parser Parser;
     smap vres;
     string pos;
     Parser.getgrammar(Node);
     string s=Node.surface();
     if (s.size() >3){
          //println("INITIAL S ", s, Node.pos());
          MAX_EDIT = min(MAX_EDIT, s.size()/2);
          map nlems;
          nlems  = au.editdistance(s, 0, a_nocase)[0];
          //println("edit dist 0:", nlems);
          string lem;
	  
	  float bestLM_lemma = getTrigramLMValue(leftLemma, Node.lemma(), rightLemma, lm);
          if (nlems.size()>0){
               //println(nlems);
               bestLM_lemma = bestLM_lemma;// + log(nlems.keys()[0].split("prob=")[1].split("+")[0]);
          }
          else{
               bestLM_lemma = bestLM_lemma;// + log(0.000001);
          }
          //println(s, bestLM_lemma);
	  nlems =  au.editdistance(s, MAX_EDIT,  a_first|a_change|a_delete|a_insert|a_switch|a_nocase)[0];
	  //println("edit dist 2:", nlems);
          string corr_lemma_withFeats;
          boolean addNewReading = false;
          fmap bestReading;     
          string bestCorrLemma = Node.lemma();
          string bestCorrSurface = Node.surface();
          string bestPos = Node.pos();
          map bestVres = vres;

          for (corr_lemma_withFeats in nlems){
               float px = log(corr_lemma_withFeats.split("prob=")[1].split("+")[0]);
               string corr_lemma = corr_lemma_withFeats.split("+")[0];
               pos = corr_lemma_withFeats.split("pos=")[1].split("+")[0];
               string xip_feats = f.up(corr_lemma)["\t":][1:];
               if (xip_feats=="+?"){
                    // if current correction wasn't found in fst: keep original node features and PoS tag
                    vres = Node.features();
                    vres.pop("lemme");
                    vres.pop("surface");
                    //pos = Node.pos();
               }
               else{
                    // add new reading with new features
                    svector vfeats=xip_feats.split("+");
                    //pos=Parser.parsefeatures(vfeats,vres);
                    //if (pos==""){
                    //     pos = Node.pos();
                    //}
               }
	       time mt;
	       //print(mt);
     	       float newLmValue = getTrigramLMValue(leftLemma, corr_lemma, rightLemma, lm);
     	       time new_mt;
     	       //print("TIME TO COMPUTE LM VALUE:", new_mt-mt);
               float newLM_lemma = newLmValue + nlems[corr_lemma_withFeats]*log(singleEditProb)+px;
	       // println(corr_lemma, newLM_lemma, nlems[corr_lemma_withFeats] );
               if (newLM_lemma > bestLM_lemma){
                 bestLM_lemma = newLM_lemma;
                 bestCorrLemma = corr_lemma;
                 bestPos = pos;
                 bestVres = vres;
               }
               //vres["spellch"]="+";
               //Node.lemma(corr_lemma, pos, vres);
               addNewReading=true;
          }

          if (addNewReading && not bestCorrLemma==Node.lemma()){
               bestVres["spellch"]="+";
               //println("BEST CORRECTION:", bestCorrLemma);
               Node.lemma(bestCorrLemma, bestPos, bestVres);
               Node.surface(bestCorrSurface);
          }
          return(addNewReading);
     }
     return(false);
}

function correct_context_pos(node Node, string leftPos, string rightPos) {
     smap vres;
     string pos;
     Parser.getgrammar(Node);
     string s=Node.surface();
     if (s.size() >3){
          //println("INITIAL S ", s, Node.pos());
          MAX_EDIT = min(MAX_EDIT, s.size()/2);
	  map bestLemmas;
          map nlems;
          nlems  = au.editdistance(s, 0, a_nocase)[0];
          //println("edit dist 0:", nlems);
          string lem;
          float bestLM_pos = getLMValue(leftPos, Node.pos(), rightPos, lm);
          if (nlems.size()>0){
               bestLM_pos = bestLM_pos + log(nlems.keys()[0].split("prob=")[1].split("+")[0]);
          }
          else{
               bestLM_pos = bestLM_pos + log(0.000001);
          }
          
	  nlems =  au.editdistance(s, MAX_EDIT,  a_first|a_change|a_delete|a_insert|a_switch|a_nocase)[0];
	  //println("edit dist 2:", nlems);
          string corr_lemma_withFeats;
          boolean addNewReading = false;
          fmap bestReading;     
          string bestCorrLemma = Node.lemma();
          string bestCorrSurface = Node.surface();
          string bestPos = Node.pos();
          map bestVres = vres;
	  
          for (corr_lemma_withFeats in nlems){
               float px = log(corr_lemma_withFeats.split("prob=")[1].split("+")[0]);
	       //println(corr_lemma_withFeats);
               string corr_lemma = corr_lemma_withFeats.split("+")[0];
               //string corr_surface = corr_lemma_withFeats.split("+")[0];
               pos = corr_lemma_withFeats.split("pos=")[1].split("+")[0];
               string xip_feats = f.up(corr_lemma)["\t":][1:];
               if (xip_feats=="+?"){
                    // if current correction wasn't found in fst: keep original node features and PoS tag
                    vres = Node.features();
                    vres.pop("lemme");
                    vres.pop("surface");
                    //pos = Node.pos();
               }
               else{
                    // add new reading with new features
                    svector vfeats=xip_feats.split("+");
               }
	       time mt;
	       //print(mt);
     	       float newLmValue = getLMValue(leftPos, pos, rightPos, lm);
     	       time new_mt;
     	       //print("TIME TO COMPUTE LM VALUE:", new_mt-mt);
               float newLM_pos = newLmValue + nlems[corr_lemma_withFeats]*log(singleEditProb) +px;
	       //println(corr_lemma, newLM_pos);
               if (newLM_pos > bestLM_pos){
                    bestLM_pos = newLM_pos;
                    bestCorrLemma = corr_lemma;
		    //println("BEST:", bestCorrLemma, px, nlems[corr_lemma_withFeats], newLmValue);
                    bestPos = pos;
                    bestVres = vres;
		    bestLemmas = [];
        	    bestLemmas[corr_lemma]= [pos, vres];
               }
	       else if (newLM_pos == bestLM_pos){
	       	     bestLemmas[corr_lemma]= [pos, vres];
	       }
               addNewReading=true;
          }

          if (addNewReading && bestCorrLemma!=Node.lemma()){
	  string bestL;
               bestVres["spellch"]="+";
               //println("BEST CORRECTION:", bestCorrLemma);
               Node.lemma(bestCorrLemma, bestPos, bestVres);
               Node.surface(bestCorrSurface);

          }
          return(addNewReading);
     }
     return(false);
}

function correct_context_right(node Node, node right){
	 return(correct_context_pos(Node, "<s>", right.pos()));
}

function correct_context_left(node Node, node left){
	 return(correct_context_pos(Node, left.pos(), "</s>"));
}

function correct_context(node Node, node left, node right){
	 if (context == "pos"){
	    return(correct_context_pos(Node, left.pos(), right.pos()));
	 }
	 if (context == "lemma"){
	    return(correct_context_lemma(Node, left.lemma(), right.lemma()));
	 }
	 return(correct(Node));
}



function correct_left(node n1, node n2){
     parser Parser;
     Parser.getgrammar(n1);
     string concatenation = n2.surface()+n1.surface();
     //println("CONCAT", concatenation);
     smap vres;
     string xip_feats = f.up(concatenation)["\t":][1:];
     if (xip_feats!="+?"){
          //println("LEFT IN AUTOMATON");
          svector vfeats=xip_feats.split("+");
          string pos=Parser.parsefeatures(vfeats,vres);
          vres["spellch"]="+";
          n1.lemma(concatenation, pos, vres);
          return(true);
     }

     return(false);
}

function correct_right(node n1, node n2){
     parser Parser;
     Parser.getgrammar(n1);
     string concatenation = n1.surface()+n2.surface();
     //println(concatenation);
     smap vres;
     string xip_feats = f.up(concatenation)["\t":][1:];
     if (xip_feats!="+?"){
          //println("RIGHT IN AUTOMATON");
          svector vfeats=xip_feats.split("+");
          string pos=Parser.parsefeatures(vfeats,vres);
          vres["spellch"]="+";
          n2.lemma(concatenation, pos, vres);
          return(true);
     }

     return(false);
}

